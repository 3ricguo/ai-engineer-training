{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a053e48-567a-407a-9f4b-ce8fd7d3991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 OpenAI API 密钥设置一个名为 OPENAI_API_KEY 的环境变量。安装 Python 库\n",
    "!pip install llama-index\n",
    "!pip install llama-index-core\n",
    "\n",
    "!pip install llama-index-llms-openai-like\n",
    "\n",
    "!pip install llama-index-llms-dashscope\n",
    "!pip install llama-index-embeddings-dashscope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ae3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK download error: File is not a zip file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 18:00:32,468 - INFO - HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "员工因私事必须本人处理的，可申请事假。事假需提前申请并获直属主管批准，紧急情况可事后补办手续。事假为无薪假，按日扣除相应工资。每月事假原则上不超过3天，全年累计不超过15天，特殊情况需经人力资源部及公司领导审批。\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "# query_engine = index.as_query_engine()\n",
    "# response = query_engine.query(\"怎么休事假？\")\n",
    "# print(response)\n",
    "\n",
    "# 配置通义千问大模型和文本向量模型\n",
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding, DashScopeTextEmbeddingModels\n",
    "\n",
    "Settings.llm = OpenAILike(\n",
    "    model=\"qwen-plus\",\n",
    "    api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    is_chat_model=True\n",
    ")\n",
    "\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V3,\n",
    "    embed_batch_size=6,\n",
    "    embed_input_length=8192\n",
    ")\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"怎么休事假？\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf0e40",
   "metadata": {},
   "source": [
    "# 思考： 为什么要用框架？\n",
    "\n",
    "\n",
    "**数据层**  \n",
    "- 如何支持多种数据源（如本地文件、云存储、数据库、API）的统一接入？  \n",
    "- 多种文件类型（PDF、DOCX、CSV、PPT）能否被自动识别并正确解析？  \n",
    "- 面对编码错误、损坏文件或加密文档，解析过程是否具备容错能力？  \n",
    "- 目录路径“data”写死，是否支持通过配置动态指定？  \n",
    "- 是否支持递归读取子目录以及按规则排除特定文件或文件夹？  \n",
    "- 用户能否自定义文件解析逻辑，例如为特定格式注册自己的解析器？  \n",
    "\n",
    ">  说明：LlamaIndex 提供 `SimpleDirectoryReader` 支持常见格式、递归读取、文件过滤（`required_exts`、`exclude_hidden`），并可通过继承 `BaseReader` 实现自定义解析器。\n",
    "\n",
    "---\n",
    "\n",
    "**索引层**  \n",
    "- 向量存储后端（如 FAISS、Chroma、Pinecone、Weaviate、Milvus）是否可灵活切换？  \n",
    "- 文档切分策略是否可配置，例如按固定长度、语义边界或段落分割？  \n",
    "- 是否支持元数据（如来源路径、作者、时间）嵌入索引以用于过滤？  \n",
    "- 索引能否持久化保存，避免每次重复构建？  \n",
    "- 新增文档时是否支持增量索引更新而非全量重建？  \n",
    "- 是否可以组合使用向量检索与关键词检索实现混合搜索？  \n",
    "\n",
    ">  说明：LlamaIndex 支持多种 `VectorStore` 集成、`NodeParser`（如 `SentenceSplitter`）可配置切分、支持元数据过滤、索引持久化（`storage_context.persist()`）、增量添加文档、以及通过 `AutoMergingRetriever` 或 `BM25Retriever + VectorIndexRetriever` 实现混合检索。\n",
    "\n",
    "---\n",
    "\n",
    "**查询层**  \n",
    "- 查询是否支持流式输出，以便前端实时展示生成内容？  \n",
    "- 是否能结合对话历史实现多轮问答和上下文理解？  \n",
    "- 不同类型的问题是否可以路由到不同的查询引擎（如规则引擎 vs 向量检索）？  \n",
    "- 是否具备意图识别能力，判断用户问题是政策咨询、流程操作还是其他类别？  \n",
    "- 如何处理模糊或歧义查询，是否支持查询重写或澄清提问？  \n",
    "\n",
    ">  说明：支持流式响应（`StreamingResponse`）、`ChatEngine` 支持对话历史、可通过 `Tool` 或自定义 `RouterQueryEngine` 实现路由、支持 `SubQuestionQueryEngine` 进行查询分解与重写。\n",
    "\n",
    "---\n",
    "\n",
    "**输出层**  \n",
    "- 返回的 `response` 对象是否能转换为标准 JSON 格式以便 API 集成？  \n",
    "- 是否可以在答案中附带引用来源、原始文本片段和置信度信息？  \n",
    "- 输出结果是否可序列化并跨网络传输？  \n",
    "- 是否提供结构化输出能力，例如返回固定 schema 的 JSON 数据？  \n",
    "- 生成内容是否经过安全检查，防止恶意 prompt 注入或泄露训练数据？  \n",
    "\n",
    ">  说明：可通过 `response.get_response()` 提取结构信息、引用节点可通过 `source_nodes` 获取、支持 `PydanticOutputParser` 生成结构化输出。但安全过滤需外部介入。\n",
    "\n",
    "---\n",
    "\n",
    "**业务层**  \n",
    "- 系统是否适配具体业务场景，如 HR 政策查询、IT 支持、员工自助服务？  \n",
    "- 不同用户角色（员工、HR、管理员）是否能看到不同范围或精度的结果？  \n",
    "- 业务规则（如事假需审批、最多3天）是否能与检索结果融合输出？  \n",
    "- 用户对回答不满意时，是否有反馈机制来收集问题并优化知识库？  \n",
    "- 高频未命中问题是否可被记录，用于后续知识补全？  \n",
    "\n",
    ">  说明：LlamaIndex 不直接实现权限控制或反馈闭环，但可通过外部逻辑集成实现“按角色过滤文档”、“记录 query 日志”等，框架本身支持元数据过滤和可扩展性。\n",
    "\n",
    "---\n",
    "\n",
    "**工程层**  \n",
    "- 文件不存在、格式不支持、解析失败等情况是否有异常捕获和处理？  \n",
    "- 大量文档加载或高并发查询时，系统性能是否可控？是否支持异步处理？  \n",
    "- 是否记录关键日志用于调试和链路追踪？  \n",
    "- 是否具备基本监控指标（如查询延迟、命中率、token 消耗）？  \n",
    "- 整个流程是否可集成到 CI/CD 流水线中，支持自动化部署？  \n",
    "\n",
    ">  说明：异常为标准 Python 异常，可捕获；支持异步加载文档和异步查询；日志使用标准 logging；token 使用可通过回调获取；工程化集成依赖外部系统，但组件本身可编程组装。\n",
    "\n",
    "---\n",
    "\n",
    "**安全层**  \n",
    "- 加载的文档是否可能包含敏感信息（如身份证号、薪资）？读取时是否需权限控制？  \n",
    "- 在文本切分和向量化过程中，是否会无意中暴露隐私内容？  \n",
    "- 是否支持对敏感字段进行自动脱敏或过滤？  \n",
    "- 输出内容是否经过合规性校验，避免生成违法或不当言论？  \n",
    "- 整个系统是否符合企业级安全审计和数据保护要求？  \n",
    "\n",
    "> 说明：LlamaIndex 本身不提供脱敏、内容过滤、权限校验等安全机制，但这些问题是合理的设计考量，可在其基础上由应用层实现。\n",
    "\n",
    "---\n",
    "\n",
    "**扩展层**  \n",
    "- 是否允许第三方开发者注册自定义数据连接器或解析插件？  \n",
    "- 是否支持接入图像、表格、扫描件等多模态内容的理解能力？  \n",
    "- 大语言模型是否可自由替换，支持本地部署模型或私有化服务？  \n",
    "- 是否提供开放接口或 SDK，供外部系统集成调用？  \n",
    "- 是否具备扩展能力以支持未来新增的数据源、索引类型或查询模式？  \n",
    "\n",
    ">  说明：LlamaIndex 设计为高度可扩展，支持自定义 Reader、NodeParser、Retriever、LLM、Embedding、Tool 等；支持 HuggingFace、Ollama、本地模型；提供 Python SDK，适合集成。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI工程化(week03)",
   "language": "python",
   "name": "week03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
